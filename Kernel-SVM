
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import linalg\n",
        "import csv \n",
        "from cvxopt import matrix as cv_opt_mat\n",
        "from cvxopt import solvers as cv_opt_solvers"
      ],
      "metadata": {
        "id": "d2_RUmmEFgnR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "df = read_csv('Xsvm.csv')\n",
        "x_o = df.values\n",
        "dfl = read_csv('ysvm.csv')\n",
        "y_o = dfl.values\n",
        "print(x_o.shape,y_o.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuRFOTdRi4z7",
        "outputId": "0d36db55-685c-40c6-b242-4c8f8e3d4494"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(499, 2) (499, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3."
      ],
      "metadata": {
        "id": "g9F9CHivCFHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### extracting  alpha's from dual form ##########\n",
        "def alphas(P,m,y):\n",
        "  q=cv_opt_mat(-np.ones((m,1)))\n",
        "  G=cv_opt_mat(-np.identity(m))\n",
        "  h=cv_opt_mat(np.zeros((m,1)))\n",
        "  A=cv_opt_mat(y.T)\n",
        "  #print(y.T.shape)\n",
        "  b=cv_opt_mat(np.zeros((1,1)))\n",
        "  sol = cv_opt_solvers.qp(P, q, G, h, A, b)\n",
        "  alp = np.array(sol['x'])\n",
        "  #print(alp.shape)\n",
        "  return alp\n",
        "\n",
        "\n",
        "def opt_parameters_vsvm(alp,labels,data,m):\n",
        "  beta_opt=0\n",
        "  s=[]\n",
        "  ## optimal beta ###\n",
        "  for i in range(m):\n",
        "    #print(i,data[i])\n",
        "    beta_opt=beta_opt+alp[i]*labels[i]*data[i]\n",
        "    if alp[i]>0:\n",
        "      s.append(i)\n",
        "  ######### beta_o ###########\n",
        "  s=np.asarray(s)\n",
        "  beta_0=0\n",
        "  for j in s:\n",
        "    t=0\n",
        "    for k in s:\n",
        "      t=alp[j]*labels[j]*np.inner(data[k],data[j])\n",
        "    beta_0+=labels[j]-t\n",
        "  beta_0=beta_0/len(s)\n",
        "  return beta_opt,beta_0\n",
        "\n",
        "\n",
        "########## y_h, error #######\n",
        "def predictions_vsvm(b_opt,b_0,x_d):\n",
        "  y_h=[]\n",
        "  y_p=np.inner(b_opt,x_d)+b_0\n",
        "  for i in range(x_d.shape[0]):\n",
        "    if (y_p[i]>0):\n",
        "      y_h.append((1))\n",
        "    else:\n",
        "      y_h.append((-1))\n",
        "  y_h=np.asarray(y_h)\n",
        "  return y_h\n",
        "#error=np.sum(abs(y_h.reshape(10,1)-labels.reshape(10,1)))"
      ],
      "metadata": {
        "id": "jZV89bvtkt7L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3,4"
      ],
      "metadata": {
        "id": "cCFxCLYZCGhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### vanilla svm ######\n",
        "cv_opt_solvers.options['show_progress'] = False\n",
        "x_svm=x_o*y_o\n",
        "m,n=x_o.shape\n",
        "#print(np.matmul(x_svm,x_svm.T).shape)\n",
        "P_vsvm=cv_opt_mat(np.inner(x_svm,x_svm))\n",
        "alp_vsvm = alphas(P_vsvm,m,y_o)\n",
        "b_opt_vsvm,b_0_vsvm=opt_parameters_vsvm(alp_vsvm,y_o,x_o,m)\n",
        "\n",
        "\n",
        "### 4. testing vsvm #####\n",
        "xt=np.array([[1.9, 0.4],[0.9, 0.9],[1.4, 1.5], [0.01, 0.005]])\n",
        "yt_h=predictions_vsvm(b_opt_vsvm,b_0_vsvm,xt)\n",
        "print(\"test data predictions with vanilla svm for the given data in ques4: \", yt_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tN28F4QnAfv",
        "outputId": "2b4813b2-4584-49f5-df8d-2ffb06f8a5dc"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data predictions with vanilla svm for the given data in ques4:  [ 1  1  1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### kernel svm ##########\n",
        "def pol_ker(xi,xj,c,p):\n",
        "  return (np.inner(xi,xj)+c)**p\n",
        "\n",
        "def exp_ker(xi,xj):\n",
        "  return np.exp(np.inner(xi,xj))\n",
        "\n",
        "def sigmoid_ker(xi,xj,kappa,c):\n",
        "  return  np.tanh(kappa * np.inner(xi, xj) + c)\n",
        " \n",
        "\n",
        "def G_RBF_ker(xi,xj,gamma):\n",
        "  d=xi-xj\n",
        "  return np.exp(-gamma*((np.linalg.norm(d))**2))\n",
        "\n",
        "\n",
        "def gauss_ker(xi,xj,sigma):\n",
        "  d=xi-xj\n",
        "  return np.exp(-((np.linalg.norm(d))**2)/(2*(sigma)**2))"
      ],
      "metadata": {
        "id": "ybZ-JbpdonXc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def opt_parameters_ksvm(alp,labels,data,m,kernel,c,p):\n",
        "  beta_opt=0\n",
        "  s=[]\n",
        "  ## optimal beta ###\n",
        "  for i in range(m):\n",
        "    beta_opt=beta_opt+alp[i]*labels[i]*data[i]\n",
        "    if alp[i]>0:\n",
        "      s.append(i)\n",
        "  ######### beta_o ###########\n",
        "  #print(\"beta_opt\",beta_opt)\n",
        "  s=np.asarray(s)\n",
        "  beta_0=0\n",
        "  for j in s:\n",
        "    t=0\n",
        "    for k in s:\n",
        "      if kernel==\"polynomial\":\n",
        "        #print(\"inside pol\",k)\n",
        "        t=alp[j]*labels[j]*pol_ker(data[k],data[j],c,p)\n",
        "      elif kernel==\"exponential\":\n",
        "        t=alp[j]*labels[j]*exp_ker(data[k],data[j])\n",
        "      elif kernel==\"sigmoid\":\n",
        "        t=alp[j]*labels[j]*sigmoid_ker(data[k],data[j],p,c)\n",
        "      elif kernel==\"gaussian\":\n",
        "        t=alp[j]*labels[j]*gauss_ker(data[k],data[j],p)\n",
        "      elif kernel==\"GRBF\":\n",
        "        t=alp[j]*labels[j]*G_RBF_ker(data[k],data[j],p)\n",
        "    beta_0+=labels[j]-t\n",
        "  beta_0=beta_0/len(s)\n",
        "  return np.array(beta_opt),beta_0\n",
        "\n",
        "\n",
        "########## y_h, error #######\n",
        "def predictions_ksvm(b_opt,b_0,x_d,kernel,c,p):\n",
        "  y_h=[]\n",
        "  \n",
        "  if kernel==\"polynomial\":\n",
        "    y_p=pol_ker(b_opt,x_d,c,p)+b_0\n",
        "  elif kernel==\"exponential\":\n",
        "    y_p=exp_ker(b_opt,x_d)+b_0\n",
        "    \n",
        "  elif kernel==\"sigmoid\":\n",
        "    y_p=sigmoid_ker(b_opt,x_d,p,c)+b_0\n",
        "  elif kernel==\"gaussian\":\n",
        "    y_p=[]\n",
        "    for i in range(len(x_d)):\n",
        "      y_p.append(gauss_ker(b_opt,x_d[i],p)+b_0)\n",
        "  elif kernel==\"G_RBF\":\n",
        "    y_p=[]\n",
        "    for i in range(len(x_d)):\n",
        "      y_p.append(G_RBF_ker(b_opt,x_d[i],p)+b_0)\n",
        "   \n",
        "   \n",
        "  for i in range(x_d.shape[0]):\n",
        "    if (y_p[i]>0):\n",
        "      y_h.append((1))\n",
        "    else:\n",
        "      y_h.append((-1))\n",
        "  y_h=np.asarray(y_h)\n",
        "  return y_h\n"
      ],
      "metadata": {
        "id": "cikzJX1f_vbK"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5."
      ],
      "metadata": {
        "id": "nFnt982MB520"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N=1000\n",
        "lr2=0.01\n",
        "c1=np.random.randint(2, size=N)\n",
        "c2=np.random.randint(2, size=N)\n",
        "gt_xor=c1^c2\n",
        "noise=np.random.normal(0,0.01,size=N) ####adding noise\n",
        "n_a1=c1+noise\n",
        "n_a2=c2+noise\n",
        "xor_o=np.hstack((np.reshape(n_a1,(N,1)),np.reshape(n_a2,(N,1))))\n",
        "gt_xor=(np.reshape(gt_xor,(N,1)))\n",
        "for i in range(N):\n",
        "  if gt_xor[i]==0:\n",
        "    gt_xor[i]=-1\n",
        "gt_xor=gt_xor.astype(np.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU0LqS4mV_1L",
        "outputId": "54b213bc-5bd7-4277-c7f5-856857a4a386"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c=0.5,p=7\n",
        "###### polynomial ker (<x,y> )^3 #########\n",
        "c=0\n",
        "p=3\n",
        "\n",
        "Hp=pol_ker(xor_o,xor_o,c,p)\n",
        "y_mat1=np.repeat(gt_xor, repeats=N)\n",
        "y_mat2= y_mat1.reshape((N,int(len(y_mat1)/N)))\n",
        "\n",
        "P_ksvmp=cv_opt_mat(y_mat2*Hp*(y_mat2.T))\n",
        "alp_ksvmp = alphas(P_ksvmp,N,gt_xor)\n",
        "b_opt_ksvmp,b_0_ksvmp=opt_parameters_ksvm(alp_ksvmp,gt_xor,xor_o,N,\"polynomial\",c,p)\n",
        "\n",
        "    ### testing ksvm #####\n",
        "xt_xor=np.array([[0,0],[0,1],[1,0], [1,1]])\n",
        "yt_h_xorp=predictions_ksvm(b_opt_ksvmp,b_0_ksvmp,xt_xor,\"polynomial\",c,p)\n",
        "print(\"xor test predictions for pol ker svm : \", yt_h_xorp)\n",
        "\n",
        "\n",
        "\n",
        "###### exponential ker ##########\n",
        "He=exp_ker(xor_o,xor_o)\n",
        "P_ksvme=cv_opt_mat(y_mat2*He*(y_mat2.T))\n",
        "alp_ksvme = alphas(P_ksvme,N,gt_xor)\n",
        "b_opt_ksvme,b_0_ksvme=opt_parameters_ksvm(alp_ksvme,gt_xor,xor_o,N,\"exponetial\",0,0)\n",
        "\n",
        "    ### testing ksvm #####\n",
        "xt_xor=np.array([[0,0],[0,1],[1,0], [1,1]])\n",
        "yt_h_xore=predictions_ksvm(b_opt_ksvme,b_0_ksvme,xt_xor,\"exponential\",0,0)\n",
        "print(\"xor test predictions for exp ker svm : \", yt_h_xore)\n",
        "\n",
        "\n",
        "\n",
        "###### sigmoid ker ##########\n",
        "con=3\n",
        "k=0.01\n",
        "Hs=sigmoid_ker(xor_o,xor_o,k,con)\n",
        "P_ksvms=cv_opt_mat(y_mat2*Hs*(y_mat2.T))\n",
        "alp_ksvms = alphas(P_ksvms,N,gt_xor)\n",
        "b_opt_ksvms,b_0_ksvms=opt_parameters_ksvm(alp_ksvms,gt_xor,xor_o,N,\"sigmoid\",con,k)\n",
        "yp_ksvms = predictions_ksvm(b_opt_ksvms,b_0_ksvms,xor_o,\"sigmoid\",con,k)\n",
        "yp_ksvms=yp_ksvms.reshape((N,1))\n",
        "        ### testing ksvm #####\n",
        "xt_xor=np.array([[0,0],[0,1],[1,0], [1,1]])\n",
        "yt_h_xors=predictions_ksvm(b_opt_ksvms,b_0_ksvms,xt_xor,\"sigmoid\",con,k)\n",
        "print(\"xor test predictions for sigmoid ker svm: \", yt_h_xors)\n",
        "\n",
        "\n",
        "\n",
        "###### gaussian ker ##########\n",
        "sig=0.01\n",
        "\n",
        "P_ksvmg=cv_opt_mat(y_mat2*gauss_ker(xor_o,xor_o,sig)*(y_mat2.T))\n",
        "alp_ksvmg = alphas(P_ksvmg,N,gt_xor)\n",
        "b_opt_ksvmg,b_0_ksvmg=opt_parameters_ksvm(alp_ksvmg,gt_xor,xor_o,N,\"gaussian\",0,sig)\n",
        "\n",
        "    ### testing ksvm #####\n",
        "xt_xor=np.array([[0,0],[0,1],[1,0], [1,1]])\n",
        "yt_h_xorg=predictions_ksvm(b_opt_ksvmg,b_0_ksvmg,xt_xor,\"gaussian\",0,sig)\n",
        "print(\"xor test predictions for gaussian ker svm : \", yt_h_xorg)\n",
        "\n",
        "\n",
        "###### RBF ker ##########\n",
        "g=0.25 #gamma\n",
        "\n",
        "P_ksvmR=cv_opt_mat(y_mat2*G_RBF_ker(xor_o,xor_o,g)*(y_mat2.T))\n",
        "alp_ksvmR = alphas(P_ksvmR,N,gt_xor)\n",
        "b_opt_ksvmR,b_0_ksvmR=opt_parameters_ksvm(alp_ksvmR,gt_xor,xor_o,N,\"G_RBF\",0,g)\n",
        "\n",
        "    ### testing ksvm #####\n",
        "xt_xor=np.array([[0,0],[0,1],[1,0], [1,1]])\n",
        "yt_h_xorR=predictions_ksvm(b_opt_ksvmR,b_0_ksvmR,xt_xor,\"G_RBF\",0,g)\n",
        "print(\"xor test predictions for RBF ker svm : \", yt_h_xorR)\n",
        "\n",
        "\n",
        "#### vanilla svm for xor ######\n",
        "cv_opt_solvers.options['show_progress'] = False\n",
        "x_ksvm=xor_o*gt_xor\n",
        "\n",
        "P_vsvmx=cv_opt_mat(np.inner(x_ksvm,x_ksvm))\n",
        "alp_vsvmx = alphas(P_vsvmx,N,gt_xor)\n",
        "b_opt_vsvmx,b_0_vsvmx=opt_parameters_vsvm(alp_vsvmx,gt_xor,xor_o,N)\n",
        "\n",
        "\n",
        "  ### testing vsvm #####\n",
        "xt_xor=np.array([[0,0],[0,1],[1,0], [1,1]])\n",
        "yt_hxor=predictions_vsvm(b_opt_vsvmx,b_0_vsvmx,xt)\n",
        "print(\"xor test predictions for vanilla svm: \", yt_hxor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mymMoPuTHFCT",
        "outputId": "85932a20-13e7-4788-a527-6fbda09a9ac3"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xor test predictions for pol ker svm :  [-1  1  1  1]\n",
            "xor test predictions for exp ker svm :  [1 1 1 1]\n",
            "xor test predictions for sigmoid ker svm:  [ 1  1  1 -1]\n",
            "xor test predictions for gaussian ker svm :  [-1 -1 -1 -1]\n",
            "xor test predictions for RBF ker svm :  [-1 -1 -1 -1]\n",
            "xor test predictions for vanilla svm:  [-1 -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictions obtained using different kernels are not equal.\n",
        "The accuracy of polynomial kernel svm and sigmoid kernel svm is 25% greater than that of vanilla svm. \n",
        "However, the results are inconsistent, possibly due to randomly choosing the parameter values for the kernel. "
      ],
      "metadata": {
        "id": "gFrto-AqANrL"
      }
    }
  ]
}
